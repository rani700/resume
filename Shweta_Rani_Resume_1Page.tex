%-------------------------
% ATS-Friendly 1-Page Data Engineer Resume
% Author: Shweta Rani
%-------------------------

\documentclass[letterpaper,10pt]{article}

\usepackage{latexsym}
\usepackage[empty]{fullpage}
\usepackage{titlesec}
\usepackage{marvosym}
\usepackage[usenames,dvipsnames]{color}
\usepackage{verbatim}
\usepackage{enumitem}
\usepackage[hidelinks]{hyperref}
\usepackage{fancyhdr}
\usepackage[english]{babel}
\usepackage{tabularx}
\usepackage{fontawesome5}
\usepackage{multicol}
\setlength{\multicolsep}{-3.0pt}
\setlength{\columnsep}{-1pt}
\input{glyphtounicode}

%----------PAGE SETUP----------
\pagestyle{fancy}
\fancyhf{}
\fancyfoot{}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}

% Optimized margins for full 1-page
\addtolength{\oddsidemargin}{-0.55in}
\addtolength{\evensidemargin}{-0.55in}
\addtolength{\textwidth}{1.1in}
\addtolength{\topmargin}{-0.5in}
\addtolength{\textheight}{1.1in}

\urlstyle{same}
\flushbottom
\raggedright
\setlength{\tabcolsep}{0in}

% Section formatting
\titleformat{\section}{
  \vspace{-4pt}\scshape\raggedright\large\bfseries
}{}{0em}{}[\color{black}\titlerule \vspace{-5pt}]

\pdfgentounicode=1

%-------------------------
% Custom commands
\newcommand{\resumeItem}[1]{
  \item\small{
    {#1 \vspace{-2pt}}
  }
}

\newcommand{\resumeSubheading}[4]{
  \vspace{-2pt}\item
    \begin{tabular*}{1.0\textwidth}[t]{l@{\extracolsep{\fill}}r}
      \textbf{#1} & \textbf{\small #2} \\
      \textit{\small#3} & \textit{\small #4} \\
    \end{tabular*}\vspace{-7pt}
}

\newcommand{\resumeProjectHeading}[2]{
    \item
    \begin{tabular*}{1.001\textwidth}{l@{\extracolsep{\fill}}r}
      \small#1 & \textbf{\small #2}\\
    \end{tabular*}\vspace{-7pt}
}

\renewcommand\labelitemi{$\vcenter{\hbox{\tiny$\bullet$}}$}
\renewcommand\labelitemii{$\vcenter{\hbox{\tiny$\bullet$}}$}

\newcommand{\resumeSubHeadingListStart}{\begin{itemize}[leftmargin=0.0in, label={}]}
\newcommand{\resumeSubHeadingListEnd}{\end{itemize}}
\newcommand{\resumeItemListStart}{\begin{itemize}[leftmargin=0.15in]}
\newcommand{\resumeItemListEnd}{\end{itemize}\vspace{-5pt}}

%-------------------------------------------
\begin{document}

%----------HEADING----------
\begin{center}
    {\Huge \scshape Shweta Rani} \\ \vspace{3pt}
    \small 
    \faPhone\ +91-7668681196 \quad $|$ \quad
    \href{mailto:shwetanimesh700@gmail.com}{\faEnvelope\ \underline{shwetanimesh700@gmail.com}} \quad $|$ \quad
    \href{https://linkedin.com/in/shwetarani24}{\faLinkedin\ \underline{LinkedIn}} \quad $|$ \quad
    \href{https://github.com/rani700}{\faGithub\ \underline{GitHub}} \quad $|$ \quad
    \href{https://youtube.com/@ShwetaNimesh}{\faYoutube\ \underline{YouTube}}
    \vspace{-8pt}
\end{center}

%-----------SUMMARY-----------
\section{Professional Summary}
\small{
Data Engineer with \textbf{2+ years} of experience building scalable ETL/ELT pipelines, real-time streaming solutions, and cloud-based data architectures. Expertise in \textbf{Azure, Python, SQL, Snowflake, Databricks} and \textbf{Apache NiFi}. Published researcher (Springer Singapore) and technical content creator building the Data Engineering community.
}
\vspace{-5pt}

%-----------TECHNICAL SKILLS-----------
\section{Technical Skills}
\begin{tabular}{@{} l @{\hspace{10pt}} l}
    \textbf{Data Engineering:} & ETL/ELT Pipelines, Data Warehousing, Data Modeling, CDC, Real-time Streaming, SnowPipe \\
    \textbf{Cloud \& Big Data:} & Azure (Data Factory, Functions), Snowflake, Databricks, AWS (S3, Lambda, EC2) \\
    \textbf{Processing:} & Apache Spark, Apache NiFi, Apache Airflow \\
    \textbf{Programming:} & Python, SQL, PySpark \\
    \textbf{Databases:} & Snowflake, MySQL, Delta Lake \\
    \textbf{Tools \& AI:} & Docker, Git, Linux, Jupyter, Jira, Generative AI, LLMs \\
\end{tabular}
\vspace{-5pt}

%-----------EXPERIENCE-----------
\section{Professional Experience}
  \resumeSubHeadingListStart

    \resumeSubheading
      {WNS}{Jul 2024 -- Present}
      {Data Engineer}{Gurugram, India}
      \resumeItemListStart
        \resumeItem{Design and implement \textbf{end-to-end ETL/ELT pipelines} using Python, SQL, and Azure to process large-scale data volumes}
        \resumeItem{Build \textbf{real-time data streaming} architectures using Apache NiFi and Snowflake with significantly reduced latency}
        \resumeItem{Develop automated \textbf{data quality frameworks} with validation checks ensuring high data accuracy across pipelines}
        \resumeItem{Optimize SQL queries and data workflows resulting in enhanced performance and cost efficiency}
        \resumeItem{Collaborate with cross-functional teams to translate business requirements into scalable data solutions}
      \resumeItemListEnd

    \resumeSubheading
      {Airtrik}{Dec 2023 -- Jan 2025}
      {Data Engineer}{Noida, India}
      \resumeItemListStart
        \resumeItem{Built scalable data pipelines using Python, Apache NiFi, and \textbf{AWS (EC2, S3, Lambda)} for enterprise data integration}
        \resumeItem{Implemented \textbf{CDC using SnowPipe} and Snowflake streams/tasks for near real-time incremental data processing}
        \resumeItem{Designed data models and optimized Snowflake warehouse configurations for improved query performance}
        \resumeItem{Containerized data applications using \textbf{Docker}, significantly reducing deployment time across environments}
      \resumeItemListEnd

    \resumeSubheading
      {Astrea IT Services}{Jul 2020 -- Feb 2022}
      {Software Developer}{Noida, India}
      \resumeItemListStart
        \resumeItem{Developed \textbf{Salesforce solutions} including custom triggers, Visualforce pages, \textbf{Apex code}, and \textbf{SOQL queries}}
        \resumeItem{Created \textbf{custom workflows} and \textbf{process automations}; participated in code reviews and requirements gathering}
      \resumeItemListEnd

  \resumeSubHeadingListEnd
\vspace{-10pt}

%-----------PROJECTS-----------
\section{Projects}
    \resumeSubHeadingListStart
    
      \resumeProjectHeading
          {\textbf{End-to-End GenAI Data Agent} $|$ \emph{Databricks, Llama 3.3, Streamlit, Spark SQL, Python} $|$ \href{https://github.com/rani700/Databricks_Ecomm_Data_Platform}{\underline{GitHub}}}{}
          \resumeItemListStart
            \resumeItem{Built \textbf{GenAI Data Agent} leveraging Llama 3.3 on Databricks with \textbf{Medallion Architecture} (Bronze/Silver/Gold)}
            \resumeItem{Implemented \textbf{custom AI Agent} in Streamlit that translates natural language to optimized Spark SQL queries}
            \resumeItem{Enabled business users to query massive e-commerce datasets without requiring SQL knowledge}
          \resumeItemListEnd
          \vspace{-6pt}
    
      \resumeProjectHeading
          {\textbf{Real-time Data Streaming Pipeline} $|$ \emph{Apache NiFi, AWS, Snowflake, SnowPipe, Docker} $|$ \href{https://github.com/rani700/RealTime-Data-Streaming-using-Apache-Nifi-AWS-and-Snowflake}{\underline{GitHub}} $|$ \href{https://www.youtube.com/watch?v=wH_MlgZoMhA}{\underline{Demo}}}{}
          \resumeItemListStart
            \resumeItem{Architected end-to-end streaming pipeline: \textbf{EC2 $\rightarrow$ Apache NiFi $\rightarrow$ S3 $\rightarrow$ SnowPipe $\rightarrow$ Snowflake}}
            \resumeItem{Implemented \textbf{Change Data Capture (CDC)} using Snowflake streams and tasks for incremental data processing}
            \resumeItem{Containerized entire solution using Docker Compose for consistent deployment and scalability}
          \resumeItemListEnd
          \vspace{-6pt}
          
      \resumeProjectHeading
          {\textbf{Spotify ETL Pipeline} $|$ \emph{AWS Lambda, S3, CloudWatch, Snowflake, Python} $|$ \href{https://github.com/rani700/SpotifyData-ETL-Pipeline}{\underline{GitHub}} $|$ \href{https://www.youtube.com/watch?v=rFcpMrcK25M}{\underline{Demo}}}{}
          \resumeItemListStart
            \resumeItem{Built \textbf{serverless ETL pipeline} using AWS Lambda to extract, transform, and load Spotify API data into Snowflake}
            \resumeItem{Automated pipeline execution with CloudWatch triggers; implemented data validation and error handling}
            \resumeItem{Designed \textbf{star schema data model} in Snowflake for efficient analytical queries}
          \resumeItemListEnd
          \vspace{-6pt}
    
      \resumeProjectHeading
          {\textbf{Automated Daily Content Ingestion Pipeline} $|$ \emph{Python, Docker, GitHub, Azure ADF, Azure App Service} $|$ \href{https://github.com/rani700/Idea-of-the-day}{\underline{GitHub}}}{}
          \resumeItemListStart
            \resumeItem{Architected \textbf{automated content ingestion pipeline} using \textbf{Azure Data Factory} for daily web scraping with \textbf{Container Registry} integration and GitHub-based automated deployment}
            \resumeItem{Built \textbf{microservices architecture}: Scraper service + Viewer App (Azure App Service) with CI/CD workflows}
          \resumeItemListEnd
          
    \resumeSubHeadingListEnd
\vspace{-10pt}

%-----------EDUCATION-----------
\section{Education}
  \resumeSubHeadingListStart
    \resumeSubheading
      {Gautam Buddha University}{Aug 2015 -- Dec 2020}
      {Integrated B.Tech (Computer Science) + M.Tech (AI \& Robotics) -- \textbf{CGPA: 8.22 / 8.36}}{Greater Noida, India}
  \resumeSubHeadingListEnd
\vspace{-10pt}

%-----------ADDITIONAL-----------
\section{Additional}
 \begin{itemize}[leftmargin=0.15in, label={}]
    \small{\item{
     $\bullet$ \textbf{Research Publication}: \href{https://link.springer.com/book/10.1007/978-981-15-8335-3}{\underline{Data Imputation in WSN using Deep Learning}} -- Springer Singapore (ICDAM 2021) \\
     $\bullet$ \textbf{Community}: Building Data Engineering community on \href{https://youtube.com/@ShwetaNimesh}{\underline{YouTube}}
    }}
 \end{itemize}

%-------------------------------------------
\end{document}
