%-------------------------
% ATS-Friendly 1-Page Data Engineer Resume
% Author: Shweta Rani
%-------------------------

\documentclass[letterpaper,10pt]{article}

\usepackage{latexsym}
\usepackage[empty]{fullpage}
\usepackage{titlesec}
\usepackage{marvosym}
\usepackage[usenames,dvipsnames]{color}
\usepackage{verbatim}
\usepackage{enumitem}
\usepackage[hidelinks]{hyperref}
\usepackage{fancyhdr}
\usepackage[english]{babel}
\usepackage{tabularx}
\usepackage{fontawesome5}
\usepackage{multicol}
\setlength{\multicolsep}{-3.0pt}
\setlength{\columnsep}{-1pt}
\input{glyphtounicode}

%----------PAGE SETUP----------
\pagestyle{fancy}
\fancyhf{}
\fancyfoot{}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}

% Optimized margins for full 1-page
\addtolength{\oddsidemargin}{-0.55in}
\addtolength{\evensidemargin}{-0.55in}
\addtolength{\textwidth}{1.1in}
\addtolength{\topmargin}{-0.5in}
\addtolength{\textheight}{1.1in}

\urlstyle{same}
\raggedbottom
\raggedright
\setlength{\tabcolsep}{0in}

% Section formatting
\titleformat{\section}{
  \vspace{-4pt}\scshape\raggedright\large\bfseries
}{}{0em}{}[\color{black}\titlerule \vspace{-5pt}]

\pdfgentounicode=1

%-------------------------
% Custom commands
\newcommand{\resumeItem}[1]{
  \item\small{
    {#1 \vspace{-2pt}}
  }
}

\newcommand{\resumeSubheading}[4]{
  \vspace{-2pt}\item
    \begin{tabular*}{1.0\textwidth}[t]{l@{\extracolsep{\fill}}r}
      \textbf{#1} & \textbf{\small #2} \\
      \textit{\small#3} & \textit{\small #4} \\
    \end{tabular*}\vspace{-7pt}
}

\newcommand{\resumeProjectHeading}[2]{
    \item
    \begin{tabular*}{1.001\textwidth}{l@{\extracolsep{\fill}}r}
      \small#1 & \textbf{\small #2}\\
    \end{tabular*}\vspace{-7pt}
}

\renewcommand\labelitemi{$\vcenter{\hbox{\tiny$\bullet$}}$}
\renewcommand\labelitemii{$\vcenter{\hbox{\tiny$\bullet$}}$}

\newcommand{\resumeSubHeadingListStart}{\begin{itemize}[leftmargin=0.0in, label={}]}
\newcommand{\resumeSubHeadingListEnd}{\end{itemize}}
\newcommand{\resumeItemListStart}{\begin{itemize}[leftmargin=0.15in]}
\newcommand{\resumeItemListEnd}{\end{itemize}\vspace{-5pt}}

%-------------------------------------------
\begin{document}

%----------HEADING----------
\begin{center}
    {\Huge \scshape Shweta Rani} \\ \vspace{3pt}
    \small 
    \faPhone\ +91-7668681196 \quad $|$ \quad
    \href{mailto:shwetanimesh700@gmail.com}{\faEnvelope\ \underline{shwetanimesh700@gmail.com}} \quad $|$ \quad
    \href{https://linkedin.com/in/shwetarani24}{\faLinkedin\ \underline{LinkedIn}} \quad $|$ \quad
    \href{https://github.com/rani700}{\faGithub\ \underline{GitHub}} \quad $|$ \quad
    \href{https://youtube.com/@ShwetaNimesh}{\faYoutube\ \underline{YouTube}}
    \vspace{-8pt}
\end{center}

%-----------SUMMARY-----------
\section{Professional Summary}
\small{
Data Engineer with \textbf{4+ years} of experience building scalable ETL/ELT pipelines, real-time streaming solutions, and cloud-based data architectures. Expertise in \textbf{AWS, Snowflake, Databricks, Apache NiFi}, and \textbf{Python}. Published researcher (Springer Singapore) and technical content creator building the Data Engineering community. Proven track record of \textbf{reducing data latency by 60\%}, \textbf{improving query performance by 40\%}, and \textbf{processing 10M+ records daily}.
}
\vspace{-10pt}

%-----------TECHNICAL SKILLS-----------
\section{Technical Skills}
\begin{tabular}{@{} l l}
    \textbf{Data Engineering:} & ETL/ELT Pipelines, Data Warehousing, Data Modeling, CDC, Real-time Streaming, SnowPipe \\
    \textbf{Cloud \& Big Data:} & AWS (S3, Lambda, EC2, Glue, Redshift), Azure (Data Factory, Synapse), Snowflake, Databricks \\
    \textbf{Processing:} & PySpark, Apache Spark, Apache NiFi, Apache Airflow, Kafka \\
    \textbf{Programming:} & Python, SQL, PySpark, Bash/Shell Scripting \\
    \textbf{Databases:} & Snowflake, PostgreSQL, MySQL, MongoDB, Redshift, Delta Lake \\
    \textbf{Tools:} & Docker, Git, Linux, Power BI, Tableau, Jupyter, Jira \\
\end{tabular}
\vspace{-8pt}

%-----------EXPERIENCE-----------
\section{Professional Experience}
  \resumeSubHeadingListStart

    \resumeSubheading
      {WNS}{Jul 2024 -- Present}
      {Data Engineer}{Gurugram, India}
      \resumeItemListStart
        \resumeItem{Design and implement \textbf{end-to-end ETL/ELT pipelines} using Python, SQL, and AWS to process \textbf{10M+ records daily}}
        \resumeItem{Build \textbf{real-time data streaming} architectures using Apache NiFi and Snowflake, \textbf{reducing data latency by 60\%}}
        \resumeItem{Develop automated \textbf{data quality frameworks} with validation checks ensuring \textbf{99\% data accuracy} across pipelines}
        \resumeItem{Optimize SQL queries and data workflows resulting in \textbf{40\% improvement} in performance and cost reduction}
        \resumeItem{Collaborate with cross-functional teams to translate business requirements into scalable data solutions}
      \resumeItemListEnd

    \resumeSubheading
      {Airtrik}{Dec 2023 -- Jan 2025}
      {Data Engineer}{Noida, India}
      \resumeItemListStart
        \resumeItem{Built scalable data pipelines using Python, Apache NiFi, and \textbf{AWS (EC2, S3, Lambda)} for enterprise data integration}
        \resumeItem{Implemented \textbf{CDC using SnowPipe} and Snowflake streams/tasks for near real-time incremental data processing}
        \resumeItem{Designed data models and optimized Snowflake warehouse configurations for improved query performance}
        \resumeItem{Containerized data applications using \textbf{Docker}, reducing deployment time by \textbf{50\%} across environments}
      \resumeItemListEnd

    \resumeSubheading
      {Astrea IT Services}{Jul 2020 -- Feb 2022}
      {Software Developer}{Noida, India}
      \resumeItemListStart
        \resumeItem{Developed Python and SQL-based applications; optimized database schemas improving query performance by \textbf{35\%}}
        \resumeItem{Built automated data processing scripts and REST APIs for internal analytics and reporting systems}
        \resumeItem{Collaborated in agile environment, participating in code reviews and ensuring high-quality deliverables}
      \resumeItemListEnd

  \resumeSubHeadingListEnd
\vspace{-14pt}

%-----------PROJECTS-----------
\section{Projects}
    \resumeSubHeadingListStart
    
      \resumeProjectHeading
          {\textbf{Real-time Data Streaming Pipeline} $|$ \emph{Apache NiFi, AWS, Snowflake, SnowPipe, Docker} $|$ \href{https://github.com/rani700/RealTime-Data-Streaming-using-Apache-Nifi-AWS-and-Snowflake}{\underline{GitHub}} $|$ \href{https://www.youtube.com/watch?v=wH_MlgZoMhA}{\underline{Demo}}}{}
          \resumeItemListStart
            \resumeItem{Architected end-to-end streaming pipeline: \textbf{EC2 $\rightarrow$ Apache NiFi $\rightarrow$ S3 $\rightarrow$ SnowPipe $\rightarrow$ Snowflake}}
            \resumeItem{Implemented \textbf{Change Data Capture (CDC)} using Snowflake streams and tasks for incremental data processing}
            \resumeItem{Containerized entire solution using Docker Compose for consistent deployment and scalability}
          \resumeItemListEnd
          \vspace{-12pt}
          
      \resumeProjectHeading
          {\textbf{Spotify ETL Pipeline} $|$ \emph{AWS Lambda, S3, CloudWatch, Snowflake, Python} $|$ \href{https://github.com/rani700/SpotifyData-ETL-Pipeline}{\underline{GitHub}} $|$ \href{https://www.youtube.com/watch?v=rFcpMrcK25M}{\underline{Demo}}}{}
          \resumeItemListStart
            \resumeItem{Built \textbf{serverless ETL pipeline} using AWS Lambda to extract, transform, and load Spotify API data into Snowflake}
            \resumeItem{Automated pipeline execution with CloudWatch triggers; implemented data validation and error handling}
            \resumeItem{Designed \textbf{star schema data model} in Snowflake for efficient analytical queries}
          \resumeItemListEnd
          \vspace{-12pt}

      \resumeProjectHeading
          {\textbf{Twitter Sentiment Analysis} $|$ \emph{Python, Flask, NLP, TextBlob} $|$ \href{https://github.com/rani700/sentiment-analysis}{\underline{GitHub}}}{}
          \resumeItemListStart
            \resumeItem{Developed real-time sentiment analysis application processing \textbf{100+ tweets per query} using NLP techniques}
            \resumeItem{Built Flask web interface with data visualization for sentiment distribution and trend analysis}
          \resumeItemListEnd
          
    \resumeSubHeadingListEnd
\vspace{-14pt}

%-----------EDUCATION-----------
\section{Education}
  \resumeSubHeadingListStart
    \resumeSubheading
      {Gautam Buddha University}{Aug 2015 -- Dec 2020}
      {Integrated B.Tech (Computer Science) + M.Tech (AI \& Robotics) -- \textbf{CGPA: 8.22 / 8.36}}{Greater Noida, India}
  \resumeSubHeadingListEnd
\vspace{-12pt}

%-----------CERTIFICATIONS & PUBLICATIONS-----------
\section{Certifications \& Publications}
 \begin{itemize}[leftmargin=0.15in, label={}]
    \small{\item{
     $\bullet$ \textbf{Machine Learning} -- Stanford University (Coursera) by Andrew Ng \\
     $\bullet$ \textbf{Research Publication}: \href{https://link.springer.com/book/10.1007/978-981-15-8335-3}{\underline{Data Imputation in WSN using Deep Learning}} -- Springer Singapore (ICDAM 2021)
    }}
 \end{itemize}
\vspace{-12pt}

%-----------ADDITIONAL-----------
\section{Additional}
 \begin{itemize}[leftmargin=0.15in, label={}]
    \small{\item{
     $\bullet$ \textbf{Community}: Building Data Engineering community on \href{https://youtube.com/@ShwetaNimesh}{\underline{YouTube}} -- Technical tutorials on AWS, Snowflake, Apache NiFi \\
     $\bullet$ \textbf{Languages}: English (Professional Proficiency), Hindi (Native)
    }}
 \end{itemize}

%-------------------------------------------
\end{document}
