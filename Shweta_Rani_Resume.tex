%-------------------------
% ATS-Friendly Professional Resume
% Author: Shweta Rani
%-------------------------

\documentclass[letterpaper,11pt]{article}

\usepackage{latexsym}
\usepackage[empty]{fullpage}
\usepackage{titlesec}
\usepackage{marvosym}
\usepackage[usenames,dvipsnames]{color}
\usepackage{verbatim}
\usepackage{enumitem}
\usepackage[hidelinks]{hyperref}
\usepackage{fancyhdr}
\usepackage[english]{babel}
\usepackage{tabularx}
\usepackage{fontawesome5}
\usepackage{multicol}
\setlength{\multicolsep}{-3.0pt}
\setlength{\columnsep}{-1pt}
\input{glyphtounicode}

%----------FONT OPTIONS----------
\pagestyle{fancy}
\fancyhf{}
\fancyfoot{}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}

% Adjust margins
\addtolength{\oddsidemargin}{-0.6in}
\addtolength{\evensidemargin}{-0.5in}
\addtolength{\textwidth}{1.19in}
\addtolength{\topmargin}{-.7in}
\addtolength{\textheight}{1.4in}

\urlstyle{same}

\raggedbottom
\raggedright
\setlength{\tabcolsep}{0in}

% Sections formatting
\titleformat{\section}{
  \vspace{-4pt}\scshape\raggedright\large\bfseries
}{}{0em}{}[\color{black}\titlerule \vspace{-5pt}]

% Ensure that generated pdf is machine readable/ATS parsable
\pdfgentounicode=1

%-------------------------
% Custom commands
\newcommand{\resumeItem}[1]{
  \item\small{
    {#1 \vspace{-2pt}}
  }
}

\newcommand{\resumeSubheading}[4]{
  \vspace{-2pt}\item
    \begin{tabular*}{1.0\textwidth}[t]{l@{\extracolsep{\fill}}r}
      \textbf{#1} & \textbf{\small #2} \\
      \textit{\small#3} & \textit{\small #4} \\
    \end{tabular*}\vspace{-7pt}
}

\newcommand{\resumeSubSubheading}[2]{
    \item
    \begin{tabular*}{0.97\textwidth}{l@{\extracolsep{\fill}}r}
      \textit{\small#1} & \textit{\small #2} \\
    \end{tabular*}\vspace{-7pt}
}

\newcommand{\resumeProjectHeading}[2]{
    \item
    \begin{tabular*}{1.001\textwidth}{l@{\extracolsep{\fill}}r}
      \small#1 & \textbf{\small #2}\\
    \end{tabular*}\vspace{-7pt}
}

\newcommand{\resumeSubItem}[1]{\resumeItem{#1}\vspace{-4pt}}

\renewcommand\labelitemi{$\vcenter{\hbox{\tiny$\bullet$}}$}
\renewcommand\labelitemii{$\vcenter{\hbox{\tiny$\bullet$}}$}

\newcommand{\resumeSubHeadingListStart}{\begin{itemize}[leftmargin=0.0in, label={}]}
\newcommand{\resumeSubHeadingListEnd}{\end{itemize}}
\newcommand{\resumeItemListStart}{\begin{itemize}}
\newcommand{\resumeItemListEnd}{\end{itemize}\vspace{-5pt}}

%-------------------------------------------
%%%%%%  RESUME STARTS HERE  %%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

%----------HEADING----------
\begin{center}
    {\Huge \scshape Shweta Rani} \\ \vspace{1pt}
    New Delhi, India \\ \vspace{1pt}
    \small \raisebox{-0.1\height}\faPhone\ +91-76 68 68 1196 ~ 
    \href{mailto:shwetanimesh700@gmail.com}{\raisebox{-0.2\height}\faEnvelope\  \underline{shwetanimesh700@gmail.com}} ~ 
    \href{https://linkedin.com/in/shwetarani24}{\raisebox{-0.2\height}\faLinkedin\ \underline{linkedin.com/in/shwetarani24}} ~
    \href{https://github.com/rani700}{\raisebox{-0.2\height}\faGithub\ \underline{github.com/rani700}}
    \vspace{-8pt}
\end{center}

%-----------PROFESSIONAL SUMMARY-----------
\section{Summary}
\small{
Results-driven Data Engineer with 4+ years of experience in building scalable ETL pipelines, real-time data streaming solutions, and cloud-based data architectures. Currently working at WNS as a Data Engineer, specializing in data pipeline development, process automation, and analytics. Proficient in Python, SQL, AWS (EC2, S3, Lambda), Snowflake, Apache NiFi, and Docker. Published researcher in deep learning applications (Springer). Passionate about building data engineering community and sharing knowledge through projects and content creation. Strong track record of transforming complex data challenges into efficient, production-ready solutions.
}
\vspace{-10pt}

%-----------TECHNICAL SKILLS-----------
\section{Technical Skills}
 \begin{itemize}[leftmargin=0.15in, label={}]
    \small{\item{
     \textbf{Programming Languages}{: Python, SQL, HTML, JavaScript, CSS, C, Apex} \\
     \textbf{Cloud \& Data Platforms}{: AWS (S3, Lambda, EC2, CloudWatch), Snowflake, Apache NiFi, Apache Airflow} \\
     \textbf{Data Engineering}{: ETL/ELT Pipelines, SnowPipe, CDC (Change Data Capture), Data Streaming, Docker, Docker Compose} \\
     \textbf{Databases}{: Snowflake, MySQL, PostgreSQL, MongoDB, Amazon S3} \\
     \textbf{Data Analysis \& ML}{: Pandas, NumPy, Scikit-learn, TensorFlow, Machine Learning, Deep Learning, NLP} \\
     \textbf{Visualization \& BI}{: Power BI, Tableau, Matplotlib, Seaborn, MS Excel (Advanced)} \\
     \textbf{Tools \& Technologies}{: Git, Linux, Jupyter Notebook, Flask, Docker, VS Code, Jira}
    }}
 \end{itemize}
\vspace{-16pt}

%-----------EXPERIENCE-----------
\section{Professional Experience}
  \resumeSubHeadingListStart

    \resumeSubheading
      {WNS}{Jul 2024 -- Present}
      {Data Engineer}{Gurugram, Haryana, India}
      \resumeItemListStart
        \resumeItem{Design and implement end-to-end data pipelines using Python, SQL, and cloud technologies to process large-scale datasets}
        \resumeItem{Develop automated ETL/ELT solutions leveraging AWS services and Snowflake, reducing manual data processing time by 50\%}
        \resumeItem{Build and maintain real-time data streaming architectures using Apache NiFi for critical business analytics}
        \resumeItem{Implement data quality checks and validation frameworks ensuring 99\% data accuracy across pipelines}
        \resumeItem{Collaborate with cross-functional teams to translate business requirements into scalable data solutions}
        \resumeItem{Optimize existing data workflows resulting in 40\% improvement in query performance and cost reduction}
      \resumeItemListEnd

    \resumeSubheading
      {Airtrik}{Dec 2023 -- Jan 2025}
      {Data Engineer}{Noida, Uttar Pradesh, India}
      \resumeItemListStart
        \resumeItem{Built and maintained scalable data pipelines using Python, Apache NiFi, and AWS services (EC2, S3, Lambda)}
        \resumeItem{Designed and implemented ETL workflows for data extraction, transformation, and loading into Snowflake data warehouse}
        \resumeItem{Developed real-time data streaming solutions using SnowPipe and CDC for incremental data processing}
        \resumeItem{Created automated data quality monitoring and alerting systems to ensure data integrity}
        \resumeItem{Containerized data applications using Docker for consistent deployment across environments}
        \resumeItem{Collaborated with analytics team to optimize data models and improve reporting performance}
      \resumeItemListEnd

    \resumeSubheading
      {Astrea IT Services}{Jul 2020 -- Feb 2022}
      {Software Developer}{Noida, Uttar Pradesh, India}
      \resumeItemListStart
        \resumeItem{Developed and maintained software applications using Python, SQL, and modern web technologies}
        \resumeItem{Designed and implemented database schemas and optimized SQL queries for improved application performance}
        \resumeItem{Collaborated with team members in agile environment to deliver high-quality software solutions on schedule}
        \resumeItem{Participated in code reviews, testing, and debugging to ensure robust and maintainable codebase}
      \resumeItemListEnd

  \resumeSubHeadingListEnd
\vspace{-16pt}

%-----------PROJECTS-----------
\section{Projects}
    \resumeSubHeadingListStart
    
      \resumeProjectHeading
          {\textbf{Spotify Data ETL Pipeline} $|$ \emph{AWS, Snowflake, Python, Lambda, S3, CloudWatch} $|$ \href{https://github.com/rani700/SpotifyData-ETL-Pipeline}{\underline{GitHub}} $|$ \href{https://www.youtube.com/watch?v=rFcpMrcK25M}{\underline{Demo}}}{}
          \resumeItemListStart
            \resumeItem{Built a complete ETL pipeline for fetching global trending songs data using Spotify APIs}
            \resumeItem{Implemented serverless architecture using AWS Lambda for data extraction and transformation}
            \resumeItem{Utilized Amazon S3 for data storage, AWS CloudWatch for monitoring, and Snowflake for data warehousing}
            \resumeItem{Automated pipeline execution using triggers and scheduling for real-time data updates}
          \resumeItemListEnd
          \vspace{-13pt}
          
      \resumeProjectHeading
          {\textbf{Real-time Data Streaming Pipeline} $|$ \emph{Apache NiFi, AWS EC2, SnowPipe, Docker} $|$ \href{https://github.com/rani700/RealTime-Data-Streaming-using-Apache-Nifi-AWS-and-Snowflake}{\underline{GitHub}} $|$ \href{https://www.youtube.com/watch?v=wH_MlgZoMhA}{\underline{Demo}}}{}
          \resumeItemListStart
            \resumeItem{Architected real-time streaming service to capture data from EC2 instances and store in S3 using Apache NiFi}
            \resumeItem{Implemented SnowPipe for automated data ingestion from S3 to Snowflake staging environment}
            \resumeItem{Configured CDC (Change Data Capture) using Snowflake streams and tasks for incremental data processing}
            \resumeItem{Containerized the solution using Docker and Docker Compose for seamless deployment and scalability}
          \resumeItemListEnd
          \vspace{-13pt}
          
      \resumeProjectHeading
          {\textbf{Twitter Sentiment Analysis} $|$ \emph{Python, Flask, NLP, TextBlob, JavaScript} $|$ \href{https://github.com/rani700/sentiment-analysis}{\underline{GitHub}}}{}
          \resumeItemListStart
            \resumeItem{Developed a web application to analyze sentiment of 100+ recent tweets for any given keyword in real-time}
            \resumeItem{Applied NLP techniques and machine learning algorithms using TextBlob for sentiment classification}
            \resumeItem{Built interactive web interface using Flask, HTML, and JavaScript for user-friendly experience}
            \resumeItem{Implemented data visualization to display sentiment distribution and trend analysis}
          \resumeItemListEnd
          
    \resumeSubHeadingListEnd
\vspace{-15pt}

%-----------RESEARCH & PUBLICATIONS-----------
\section{Research \& Publications}
  \resumeSubHeadingListStart
    \resumeSubheading
      {Data Imputation in Wireless Sensor Network Using Deep Learning Techniques $|$ \href{https://link.springer.com/book/10.1007/978-981-15-8335-3}{\underline{Publication}}}{Jan 2021}
      {Data Analytics and Management (Proceedings of ICDAM)}{Springer Singapore}
      \resumeItemListStart
        \resumeItem{Published research paper on applying deep learning techniques for data imputation in wireless sensor networks}
        \resumeItem{Conducted extensive experiments and analysis to validate proposed methodology}
      \resumeItemListEnd
  \resumeSubHeadingListEnd
\vspace{-16pt}

%-----------EDUCATION-----------
\section{Education}
  \resumeSubHeadingListStart
    \resumeSubheading
      {Gautam Buddha University, Greater Noida}{Aug 2015 -- Dec 2020}
      {Integrated B.Tech + M.Tech}{Greater Noida, India}
      \resumeItemListStart
        \resumeItem{M.Tech in Artificial Intelligence and Robotics -- CGPA: 8.36}
        \resumeItem{B.Tech in Computer Science -- CGPA: 8.22}
      \resumeItemListEnd
    \vspace{-3pt}
    \resumeSubheading
      {DAV Public School, Saharanpur}{May 2014}
      {Intermediate (12th) -- 83.6\%}{Saharanpur, India}
    \vspace{-3pt}
    \resumeSubheading
      {Khalsa Montessori School, Bulandshahr}{May 2012}
      {Matriculation (10th) -- CGPA: 9.4}{Bulandshahr, India}
  \resumeSubHeadingListEnd
\vspace{-10pt}

%-----------CERTIFICATIONS & TRAINING-----------
\section{Certifications \& Training}
 \begin{itemize}[leftmargin=0.15in, label={}]
    \small{\item{
     \textbf{Machine Learning}{, Stanford University (Coursera) -- Andrew Ng} \\
     \textbf{Data Science and Machine Learning with Python}{, 6 Weeks Training Program}
    }}
 \end{itemize}
\vspace{-16pt}

%-----------ADDITIONAL-----------
\section{Additional Information}
 \begin{itemize}[leftmargin=0.15in, label={}]
    \small{\item{
     \textbf{Languages}{: English (Professional), Hindi (Native)} \\
     \textbf{YouTube}{: Building Data Engineering Community | \href{https://www.youtube.com/@ShwetaNimesh}{\underline{youtube.com/@ShwetaNimesh}} -- Technical tutorials on AWS, Snowflake, Apache NiFi} \\
     \textbf{Interests}{: Data Engineering, Cloud Computing, Machine Learning, Open Source, Technical Content Creation}
    }}
 \end{itemize}

%-------------------------------------------
\end{document}
